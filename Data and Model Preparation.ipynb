{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from joblib import load, dump \n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(sentence):\n",
    "    no_punc = [c for c in sentence if c not in string.punctuation]\n",
    "    no_punc = ''.join(no_punc)\n",
    "    no_stopwords = [w.lower() for w in no_punc.split() if (w not in stopwords_set) and (len(re.search('^\\s*[0-9]*', w)[0]) == 0)]    \n",
    "    stemmed_words = [ps.stem(w) for w in no_stopwords]\n",
    "    return stemmed_words\n",
    "\n",
    "def clean_review_len(sentence):\n",
    "    return len(clean_review(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(s):\n",
    "    vs = analyzer.polarity_scores(s)\n",
    "    if vs['compound'] >= 0.05:\n",
    "        return 2\n",
    "    elif vs['compound'] <= -0.05:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def get_strict_sentiment(s):\n",
    "    vs = analyzer.polarity_scores(s)\n",
    "    if vs['compound'] >= 0.0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_freq_table(input_df):\n",
    "    bow_transformer = CountVectorizer(analyzer=clean_review).fit(input_df['review_body'])\n",
    "    transformed_input = bow_transformer.transform(input_df['review_body'])\n",
    "    count_vect_df = pd.DataFrame(transformed_input.todense(), columns=bow_transformer.get_feature_names())\n",
    "    return count_vect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_reviews_by_sent = load('json_review_dataframe_by_sent')\n",
    "json_reviews_by_sent['sentiment'] = json_reviews_by_sent['review_body'].apply(get_sentiment)\n",
    "json_word_freq_table = create_word_freq_table(json_reviews_by_sent)\n",
    "json_word_freq_table['_sentiment'] = json_reviews_by_sent['sentiment']\n",
    "json_word_freq_table['_classification'] = json_reviews_by_sent['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num informative:  815\n",
      "Num non-informative:  1267\n",
      "Num vague:  131\n"
     ]
    }
   ],
   "source": [
    "# json_reviews_by_sent['clean_review_body'] = json_reviews_by_sent['review_body'].apply(clean_review)\n",
    "# json_reviews_by_sent['review_body'] = json_reviews_by_sent['review_body'].apply(fix_tiktok)\n",
    "# json_reviews_by_sent = load('json_review_dataframe')\n",
    "print('Num informative: ', len(json_reviews_by_sent[(json_reviews_by_sent['classification'] == 'informative')]))\n",
    "print('Num non-informative: ', len(json_reviews_by_sent[(json_reviews_by_sent['classification'] == 'non-informative')]))\n",
    "print('Num vague: ', len(json_reviews_by_sent[(json_reviews_by_sent['classification'] == 'vague')]))\n",
    "# perform whatever manipulations you want on the json_reviews_by_sent dataframe\n",
    "non_informative_df = json_reviews_by_sent[(json_reviews_by_sent['classification'] == 'non-informative')]\n",
    "informative_df = json_reviews_by_sent[(json_reviews_by_sent['classification'] == 'informative')]\n",
    "classification_df = informative_df.append(non_informative_df[:361], ignore_index=True)\n",
    "\n",
    "# drop irrelevant columns\n",
    "classification_df.drop(['review_num', 'application', 'length'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# With words_freq_table\n",
    "non_informative_df = json_word_freq_table[(json_word_freq_table['_classification'] == 'non-informative')]\n",
    "informative_df = json_word_freq_table[(json_word_freq_table['_classification'] == 'informative')]\n",
    "classification_df = informative_df.append(non_informative_df[:361], ignore_index=True)\n",
    "# classification_df = classification_df.append(json_word_freq_table[(json_word_freq_table['_classification'] == 'vague')], ignore_index=True)\n",
    "\n",
    "# trying 3 categories\n",
    "# classification_df = json_word_freq_table[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# msg_train, msg_test, label_train, label_test = train_test_split(classification_df.drop('classification', axis=1), classification_df['classification'], test_size=0.3, random_state=42)\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(classification_df.drop('_classification', axis=1), classification_df['_classification'], test_size=0.3, random_state=42)\n",
    "param_grid = {'classifier__C': [0.1,1, 10, 100, 1000], 'classifier__gamma': [1,0.1,0.01,0.001,0.0001], 'classifier__kernel': ['rbf']} \n",
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    informative       0.94      0.81      0.87       289\n",
      "non-informative       0.48      0.78      0.60        64\n",
      "\n",
      "       accuracy                           0.81       353\n",
      "      macro avg       0.71      0.80      0.73       353\n",
      "   weighted avg       0.86      0.81      0.82       353\n",
      "\n",
      "Random Forest Classifier\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    informative       0.88      0.93      0.90       235\n",
      "non-informative       0.84      0.74      0.78       118\n",
      "\n",
      "       accuracy                           0.86       353\n",
      "      macro avg       0.86      0.83      0.84       353\n",
      "   weighted avg       0.86      0.86      0.86       353\n",
      "\n",
      "SVM\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    informative       0.94      0.94      0.94       250\n",
      "non-informative       0.85      0.85      0.85       103\n",
      "\n",
      "       accuracy                           0.91       353\n",
      "      macro avg       0.89      0.90      0.89       353\n",
      "   weighted avg       0.91      0.91      0.91       353\n",
      "\n",
      "Bernoulli\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    informative       0.95      0.85      0.90       279\n",
      "non-informative       0.60      0.84      0.70        74\n",
      "\n",
      "       accuracy                           0.85       353\n",
      "      macro avg       0.77      0.84      0.80       353\n",
      "   weighted avg       0.88      0.85      0.86       353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(msg_train, label_train)\n",
    "predictions1 = mnb.predict(msg_test)\n",
    "print('Multinomial')\n",
    "print(classification_report(predictions1, label_test))\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(msg_train, label_train)\n",
    "predictions2 = rfc.predict(msg_test)\n",
    "print('Random Forest Classifier')\n",
    "print(classification_report(predictions2, label_test))\n",
    "\n",
    "# grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=0, cv=10)\n",
    "# grid.fit(msg_train, label_train)\n",
    "# predictions3 = grid.predict(msg_test)\n",
    "# print('Support Vector Machine')\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_estimator_)\n",
    "# print(classification_report(predictions3, label_test))\n",
    "\n",
    "\n",
    "svm = SVC(C = 10, gamma= 0.01)\n",
    "svm.fit(msg_train, label_train)\n",
    "predictions3 = svm.predict(msg_test)\n",
    "print('SVM')\n",
    "print(classification_report(predictions3, label_test))\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(msg_train, label_train)\n",
    "predictions4 = bnb.predict(msg_test)\n",
    "print('Bernoulli')\n",
    "print(classification_report(predictions4, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78 (+/- 0.06)\n",
      "Accuracy: 0.86 (+/- 0.07)\n",
      "Accuracy: 0.90 (+/- 0.07)\n",
      "Accuracy: 0.81 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "scores1 = cross_val_score(mnb, msg_train, label_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))\n",
    "scores2 = cross_val_score(rfc, msg_train, label_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))\n",
    "scores3 = cross_val_score(svm, msg_train, label_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std() * 2))\n",
    "scores4 = cross_val_score(bnb, msg_train, label_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-5d7c0cee2bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfc' is not defined"
     ]
    }
   ],
   "source": [
    "predictions1 = mnb.predict(msg_test)\n",
    "predictions2 = rfc.predict(msg_test)\n",
    "predictions3 = svm.predict(msg_test)\n",
    "predictions4 = bnb.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    informative       0.94      0.81      0.87       289\n",
      "non-informative       0.48      0.78      0.60        64\n",
      "\n",
      "       accuracy                           0.81       353\n",
      "      macro avg       0.71      0.80      0.73       353\n",
      "   weighted avg       0.86      0.81      0.82       353\n",
      "\n",
      "RFC\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictions2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c3c9a9c54d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RFC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Multinomial')\n",
    "print(classification_report(predictions1, label_test))\n",
    "print('RFC')\n",
    "print(classification_report(predictions2, label_test))\n",
    "print('SVM')\n",
    "print(classification_report(predictions3, label_test))\n",
    "print('Bernoulli')\n",
    "print(classification_report(predictions4, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d0b181a55774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_word_freq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_classification'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjson_reviews_by_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mjson_reviews_by_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = load('best_model')\n",
    "pred = best_model.predict(json_word_freq_table[1001:].drop('_classification', axis=1).fillna(0))\n",
    "for i in range(len(pred)):\n",
    "    if json_reviews_by_sent['classification'][1001+i] == None:\n",
    "        json_reviews_by_sent['classification'][1001+i] = pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
