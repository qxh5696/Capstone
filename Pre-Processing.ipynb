{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "# nltk.download('punkt')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "import time\n",
    "import sys, io\n",
    "from joblib import load, dump \n",
    "import pandas as pd # Pandas documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "import enchant\n",
    "import string\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  \n",
    "chrome_options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiktok_reviews = pd.read_json('json_review_files/tiktok_reviews.json') \n",
    "facebook_reviews = pd.read_json('json_review_files/facebook_reviews.json') \n",
    "snapchat_reviews = pd.read_json('json_review_files/snapchat_reviews.json') \n",
    "reddit_reviews = pd.read_json('json_review_files/reddit_reviews.json')\n",
    "spotify_reviews = pd.read_json('json_review_files/spotify_reviews.json')\n",
    "review_json_files = ['tiktok_reviews.json', 'facebook_reviews.json', 'snapchat_reviews.json', 'reddit_reviews.json', 'spotify_reviews.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_review_df = pd.DataFrame(columns=['review_body', 'found_helpful', 'application'])\n",
    "# for json_file in review_json_files:\n",
    "#     application_review = pd.read_json(json_file)\n",
    "#     application = json_file.split('_')[0]\n",
    "#     for i in range(len(application_review)):\n",
    "#         page_expansion = BeautifulSoup(application_review['review_body'][i], 'html.parser')\n",
    "#         full_review = page_expansion.find('span', {'jsname':'fbQN7e'})\n",
    "#         page_expansion = BeautifulSoup(application_review['found_helpful'][i], 'html.parser')\n",
    "#         helpful_rating = page_expansion.find('div', class_='jUL89d')\n",
    "#         helpful_rating = int(helpful_rating.text) if len(helpful_rating) != None else 0\n",
    "#         if helpful_rating > 200:\n",
    "#             json_review_df = json_review_df.append({'review_body': full_review.text, 'found_helpful': helpful_rating, 'application': application}, ignore_index=True)\n",
    "# print(len(json_review_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split by sentence\n",
    "# json_reviews_by_sent = pd.DataFrame(columns=['review_num', 'review_body', 'application', 'classification'])\n",
    "# for i in range(len(json_review_df)):\n",
    "#     review = json_review_df['review_body'][i]\n",
    "#     sentences = nltk.tokenize.sent_tokenize(review)\n",
    "#     for sentence in sentences:\n",
    "#         json_reviews_by_sent = json_reviews_by_sent.append({'review_num': i, 'review_body': sentence, 'application': json_review_df['application'][i],'classification': None},\n",
    "#                                                           ignore_index=True) \n",
    "# print(len(json_reviews_by_sent))\n",
    "# json_reviews_by_sent = json_reviews_by_sent.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label reviews as informative or uninformative\n",
    "# # DO NOT RUN THIS IF DATA IS LABELED ALREADY\n",
    "# for i in range(1000):\n",
    "#     # print(\"======================\")\n",
    "#     if json_reviews_by_sent['classification'][i] == None: \n",
    "#         print('Review ' + str(i))\n",
    "#         print(json_reviews_by_sent['review_body'][i])\n",
    "#         classification = input('Informative or non-informative? ') \n",
    "#         if classification == 'n' or classification == 'i':\n",
    "#             classification = 'non-informative' if classification == 'n' else 'informative'\n",
    "#         if classification == 'v':\n",
    "#             classification = 'vague'\n",
    "#         json_reviews_by_sent['classification'][i] = classification\n",
    "#     dump(json_reviews_by_sent, 'json_review_dataframe_by_sent', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
